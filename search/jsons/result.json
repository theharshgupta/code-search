{
    "data": [
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/gcloud_api.py",
            "function": "parse_gcloud_recognize_response(response)",
            "docstring": "Parse the Google Cloud Recognize Response into a dictionary"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/gcloud_api.py",
            "function": "get_gcloud_timestamps(response_dict)",
            "docstring": "Get the timestamps of words from a Google Cloud Recognize Response dictionary.    A timestamp is a 2D tuple of the start time and end time in milliseconds"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/analysis.py",
            "function": "process_file(path)",
            "docstring": "Calls the relevant functions once the file is uploaded by the user. Right now we are calling the emotion tagging  function  :param path: path to the audio file  :return: Nothing"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_tokenizer.py",
            "function": "test_normal()",
            "docstring": "Normal/combined usage."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_tokenizer.py",
            "function": "test_emojis()",
            "docstring": "Tokenizing emojis/emoticons/decorations."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_tokenizer.py",
            "function": "test_urls()",
            "docstring": "Tokenizing URLs."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_tokenizer.py",
            "function": "test_twitter()",
            "docstring": "Tokenizing hashtags, mentions and emails."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_tokenizer.py",
            "function": "test_phone_nums()",
            "docstring": "Tokenizing phone numbers."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_tokenizer.py",
            "function": "test_datetime()",
            "docstring": "Tokenizing dates and times."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_tokenizer.py",
            "function": "test_currencies()",
            "docstring": "Tokenizing currencies."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_tokenizer.py",
            "function": "test_num_sym()",
            "docstring": "Tokenizing combinations of numbers and symbols."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_tokenizer.py",
            "function": "test_punctuation()",
            "docstring": "Tokenizing punctuation and contractions."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_tokenizer.py",
            "function": "test_base(tests)",
            "docstring": "Base function for running tests."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_word_generator.py",
            "function": "test_only_unicode_accepted()",
            "docstring": "Non-Unicode strings raise a ValueError."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_word_generator.py",
            "function": "test_unicode_sentences_ignored_if_set()",
            "docstring": "Strings with Unicode characters tokenize to empty array if they're not allowed."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_word_generator.py",
            "function": "test_check_ascii()",
            "docstring": "check_ascii recognises ASCII words properly."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_word_generator.py",
            "function": "test_convert_unicode_word()",
            "docstring": "convert_unicode_word converts Unicode words correctly."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_word_generator.py",
            "function": "test_convert_unicode_word_ignores_if_set()",
            "docstring": "convert_unicode_word ignores Unicode words if set."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_word_generator.py",
            "function": "test_convert_unicode_chars()",
            "docstring": "convert_unicode_word correctly converts accented characters."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_finetuning.py",
            "function": "test_calculate_batchsize_maxlen()",
            "docstring": "Batch size and max length are calculated properly."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_finetuning.py",
            "function": "test_freeze_layers()",
            "docstring": "Correct layers are frozen."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_finetuning.py",
            "function": "test_change_trainable()",
            "docstring": "change_trainable() changes trainability of layers."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_finetuning.py",
            "function": "test_deepmoji_transfer_extend_embedding()",
            "docstring": "Defining deepmoji with extension."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_finetuning.py",
            "function": "test_relabel()",
            "docstring": "relabel() works with multi-class labels."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_finetuning.py",
            "function": "test_relabel_binary()",
            "docstring": "relabel() works with binary classification (no changes to labels)"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_finetuning.py",
            "function": "test_finetune_full()",
            "docstring": "finetuning using 'full'."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_finetuning.py",
            "function": "test_finetune_last()",
            "docstring": "finetuning using 'last'."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_finetuning.py",
            "function": "test_score_emoji()",
            "docstring": "Emoji predictions make sense."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_finetuning.py",
            "function": "test_encode_texts()",
            "docstring": "Text encoding is stable."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_sentence_tokenizer.py",
            "function": "test_dataset_split_parameter()",
            "docstring": "Dataset is split in the desired ratios"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_sentence_tokenizer.py",
            "function": "test_dataset_split_explicit()",
            "docstring": "Dataset is split according to given indices"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_sentence_tokenizer.py",
            "function": "test_id_to_sentence()",
            "docstring": "Tokenizing and converting back preserves the input."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/tests/test_sentence_tokenizer.py",
            "function": "test_id_to_sentence_with_unknown()",
            "docstring": "Tokenizing and converting back preserves the input, except for unknowns."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/sentence_tokenizer.py",
            "function": "tokenize_sentences(self, sentences, reset_stats=True, max_sentences=None)",
            "docstring": "Converts a given list of sentences into a numpy array according to      its vocabulary.    # Arguments:      sentences: List of sentences to be tokenized.      reset_stats: Whether the word generator's stats should be reset.      max_sentences: Maximum length of sentences. Must be set if the        length cannot be inferred from the input.    # Returns:      Numpy array of the tokenization sentences with masking,      infos,      stats    # Raises:      ValueError: When maximum length is not set and cannot be inferred."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/sentence_tokenizer.py",
            "function": "to_sentence(self, sentence_idx)",
            "docstring": "Converts a tokenized sentence back to a list of words.    # Arguments:      sentence_idx: List of numbers, representing a tokenized sentence        given the current vocabulary.    # Returns:      String created by converting all numbers back to words and joined      together with spaces."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/sentence_tokenizer.py",
            "function": "coverage(dataset, verbose=False)",
            "docstring": "Computes the percentage of words in a given dataset that are unknown.  # Arguments:    dataset: Tokenized dataset to be checked.    verbose: Verbosity flag.  # Returns:    Percentage of unknown tokens."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/filter_utils.py",
            "function": "mostly_english(words, english, pct_eng_short=0.5, pct_eng_long=0.6, ignore_special_tokens=True, min_length=2)",
            "docstring": "Ensure text meets threshold for containing English words"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/filter_utils.py",
            "function": "correct_length(words, min_words, max_words, ignore_special_tokens=True)",
            "docstring": "Ensure text meets threshold for containing English words    and that it's within the min and max words limits."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/filter_utils.py",
            "function": "remove_variation_selectors(text)",
            "docstring": "Remove styling glyph variants for Unicode characters.    For instance, remove skin color from emojis."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/filter_utils.py",
            "function": "shorten_word(word)",
            "docstring": "Shorten groupings of 3+ identical consecutive chars to 2, e.g. '!!!!' --> '!!'"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/filter_utils.py",
            "function": "process_word(word)",
            "docstring": "Shortening and converting the word to a special token if relevant."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/model_def.py",
            "function": "deepmoji_feature_encoding(maxlen, weight_path, return_attention=False)",
            "docstring": "Loads the pretrained DeepMoji model for extracting features    from the penultimate feature layer. In this way, it transforms    the text into its emotional encoding.  # Arguments:    maxlen: Maximum length of a sentence (given in tokens).    weight_path: Path to model weights to be loaded.    return_attention: If true, output will be weight of each input token      used for the prediction  # Returns:    Pretrained model for encoding text into feature vectors."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/model_def.py",
            "function": "deepmoji_emojis(maxlen, weight_path, return_attention=False)",
            "docstring": "Loads the pretrained DeepMoji model for extracting features    from the penultimate feature layer. In this way, it transforms    the text into its emotional encoding.  # Arguments:    maxlen: Maximum length of a sentence (given in tokens).    weight_path: Path to model weights to be loaded.    return_attention: If true, output will be weight of each input token      used for the prediction  # Returns:    Pretrained model for encoding text into feature vectors."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/model_def.py",
            "function": "deepmoji_architecture(nb_classes, nb_tokens, maxlen, feature_output=False, embed_dropout_rate=0, final_dropout_rate=0, embed_l2=1E-6, return_attention=False)",
            "docstring": "Returns the DeepMoji architecture uninitialized and  without using the pretrained model weights.  # Arguments:    nb_classes: Number of classes in the dataset.    nb_tokens: Number of tokens in the dataset (i.e. vocabulary size).    maxlen: Maximum length of a token.    feature_output: If True the model returns the penultimate            feature vector rather than Softmax probabilities            (defaults to False).    embed_dropout_rate: Dropout rate for the embedding layer.    final_dropout_rate: Dropout rate for the final Softmax layer.    embed_l2: L2 regularization for the embedding layerl.  # Returns:    Model with the given parameters."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/model_def.py",
            "function": "load_specific_weights(model, weight_path, exclude_names=[], extend_embedding=0, verbose=True)",
            "docstring": "Loads model weights from the given file path, excluding any    given layers.  # Arguments:    model: Model whose weights should be loaded.    weight_path: Path to file containing model weights.    exclude_names: List of layer names whose weights should not be loaded.    extend_embedding: Number of new words being added to vocabulary.    verbose: Verbosity flag.  # Raises:    ValueError if the file at weight_path does not exist."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/model_def.py",
            "function": "append_to_embedding(pretrain_weights, random_init_weights)",
            "docstring": "Uses pretrained weights for the tokens already in the vocabulary.    Remaining weights will be left with the random initialization."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/model_def.py",
            "function": "get_weights_from_hdf5(filepath)",
            "docstring": "Loads the weights from a saved Keras model into numpy arrays.    The weights are saved using Keras 2.0 so we don't need all the    conversion functionality for handling old weights."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/create_vocab.py",
            "function": "count_words_in_sentence(self, words)",
            "docstring": "Generates word counts for all tokens in the given sentence.    # Arguments:      words: Tokenized sentence whose words should be counted."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/create_vocab.py",
            "function": "save_vocab(self, path=None)",
            "docstring": "Saves the vocabulary into a file.    # Arguments:      path: Where the vocabulary should be saved. If not specified, a         randomly generated filename is used instead."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/create_vocab.py",
            "function": "get_next_word(self)",
            "docstring": "Returns next tokenized sentence from the word geneerator.    # Returns:      List of strings, representing the next tokenized sentence."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/create_vocab.py",
            "function": "count_all_words(self)",
            "docstring": "Generates word counts for all words in all sentences of the word      generator."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/create_vocab.py",
            "function": "populate_master_vocab(self, vocab_path, min_words=1, force_appearance=None)",
            "docstring": "Populates the master vocabulary using all vocabularies found in the      given path. Vocabularies should be named *.npz. Expects the      vocabularies to be numpy arrays with counts. Normalizes the counts      and combines them.    # Arguments:      vocab_path: Path containing vocabularies to be combined.      min_words: Minimum amount of occurences a word must have in order        to be included in the master vocabulary.      force_appearance: Optional vocabulary filename that will be added        to the master vocabulary no matter what. This vocabulary must        be present in vocab_path."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/create_vocab.py",
            "function": "save_vocab(self, path_count, path_vocab, word_limit=100000)",
            "docstring": "Saves the master vocabulary into a file."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/create_vocab.py",
            "function": "all_words_in_sentences(sentences)",
            "docstring": "Extracts all unique words from a given list of sentences.  # Arguments:    sentences: List or word generator of sentences to be processed.  # Returns:    List of all unique words contained in the given sentences."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/create_vocab.py",
            "function": "extend_vocab_in_file(vocab, max_tokens=10000, vocab_path=VOCAB_PATH)",
            "docstring": "Extends JSON-formatted vocabulary with words from vocab that are not    present in the current vocabulary. Adds up to max_tokens words.    Overwrites file in vocab_path.  # Arguments:    new_vocab: Vocabulary to be added. MUST have word_counts populated, i.e.      must have run count_all_words() previously.    max_tokens: Maximum number of words to be added.    vocab_path: Path to the vocabulary json which is to be extended."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/create_vocab.py",
            "function": "extend_vocab(current_vocab, new_vocab, max_tokens=10000)",
            "docstring": "Extends current vocabulary with words from vocab that are not    present in the current vocabulary. Adds up to max_tokens words.  # Arguments:    current_vocab: Current dictionary of tokens.    new_vocab: Vocabulary to be added. MUST have word_counts populated, i.e.      must have run count_all_words() previously.    max_tokens: Maximum number of words to be added.  # Returns:    How many new tokens have been added."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/finetuning.py",
            "function": "load_benchmark(path, vocab, extend_with=0)",
            "docstring": "Loads the given benchmark dataset.    Tokenizes the texts using the provided vocabulary, extending it with    words from the training dataset if extend_with > 0. Splits them into    three lists: training, validation and testing (in that order).    Also calculates the maximum length of the texts and the    suggested batch_size.  # Arguments:    path: Path to the dataset to be loaded.    vocab: Vocabulary to be used for tokenizing texts.    extend_with: If > 0, the vocabulary will be extended with up to      extend_with tokens from the training set before tokenizing.  # Returns:    A dictionary with the following fields:      texts: List of three lists, containing tokenized inputs for        training, validation and testing (in that order).      labels: List of three lists, containing labels for training,        validation and testing (in that order).      added: Number of tokens added to the vocabulary.      batch_size: Batch size.      maxlen: Maximum length of an input."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/finetuning.py",
            "function": "calculate_batchsize_maxlen(texts)",
            "docstring": "Calculates the maximum length in the provided texts and a suitable    batch size. Rounds up maxlen to the nearest multiple of ten.  # Arguments:    texts: List of inputs.  # Returns:    Batch size,    max length"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/finetuning.py",
            "function": "finetuning_callbacks(checkpoint_path, patience, verbose)",
            "docstring": "Callbacks for model training.  # Arguments:    checkpoint_path: Where weight checkpoints should be saved.    patience: Number of epochs with no improvement after which      training will be stopped.  # Returns:    Array with training callbacks that can be passed straight into    model.fit() or similar."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/finetuning.py",
            "function": "freeze_layers(model, unfrozen_types=[], unfrozen_keyword=None)",
            "docstring": "Freezes all layers in the given model, except for ones that are    explicitly specified to not be frozen.  # Arguments:    model: Model whose layers should be modified.    unfrozen_types: List of layer types which shouldn't be frozen.    unfrozen_keyword: Name keywords of layers that shouldn't be frozen.  # Returns:    Model with the selected layers frozen."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/finetuning.py",
            "function": "change_trainable(layer, trainable, verbose=False)",
            "docstring": "Helper method that fixes some of Keras' issues with wrappers and    trainability. Freezes or unfreezes a given layer.  # Arguments:    layer: Layer to be modified.    trainable: Whether the layer should be frozen or unfrozen.    verbose: Verbosity flag."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/finetuning.py",
            "function": "relabel(y, current_label_nr, nb_classes)",
            "docstring": "Makes a binary classification for a specific class in a    multi-class dataset.  # Arguments:    y: Outputs to be relabelled.    current_label_nr: Current label number.    nb_classes: Total number of classes.  # Returns:    Relabelled outputs of a given multi-class dataset into a binary    classification dataset."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/finetuning.py",
            "function": "evaluate_using_acc(model, X_test, y_test, batch_size)",
            "docstring": "Evaluation function using accuracy.  # Arguments:    model: Model to be evaluated.    X_test: Inputs of the testing set.    y_test: Outputs of the testing set.    batch_size: Batch size.  # Returns:    Accuracy of the given model."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/tokenizer.py",
            "function": "RE_EMOJI = ur\"\"\"\\ud83c[\\udf00-\\udfff]|\\ud83d[\\udc00-\\ude4f\\ude80-\\uf]|[\\u2600-\\u26FF\\u2700-\\u27BF]\"\"\"",
            "docstring": "RE_EMOJI = ur\\ud83c[\\udf00-\\udfff]|\\ud83d[\\udc00-\\ude4f\\ude80-\\udeff]|[\\u2600-\\u26FF\\u2700-\\u27BF]"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/word_generator.py",
            "function": "get_words(self, sentence)",
            "docstring": "Tokenizes a sentence into individual words.      Converts Unicode punctuation into ASCII if that option is set.      Ignores sentences with Unicode if that option is set.      Returns an empty list of words if the sentence has Unicode and      that is not allowed."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/word_generator.py",
            "function": "check_ascii(self, word)",
            "docstring": "Returns whether a word is ASCII"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/word_generator.py",
            "function": "convert_unicode_word(self, word)",
            "docstring": "Converts Unicode words to ASCII using unidecode. If Unicode is not      allowed (set as a variable during initialization), then only      punctuation that can be converted to ASCII will be allowed."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/word_generator.py",
            "function": "data_preprocess_filtering(self, line, iter_i)",
            "docstring": "To be overridden with specific preprocessing/filtering behavior      if desired.      Returns a boolean of whether the line should be accepted and the      preprocessed text.      Runs prior to tokenization."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/word_generator.py",
            "function": "data_postprocess_filtering(self, words, iter_i)",
            "docstring": "To be overridden with specific postprocessing/filtering behavior      if desired.      Returns a boolean of whether the line should be accepted and the      postprocessed text.      Runs after tokenization."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/word_generator.py",
            "function": "extract_valid_sentence_words(self, line)",
            "docstring": "Line may either a string of a list of strings depending on how      the stream is being parsed.      Domain-specific processing and filtering can be done both prior to      and after tokenization.      Custom information about the line can be extracted during the      processing phases and returned as a dict."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/DeepMoji-master/deepmoji/class_avg_finetuning.py",
            "function": "relabel(y, current_label_nr, nb_classes)",
            "docstring": "Makes a binary classification for a specific class in a    multi-class dataset.  # Arguments:    y: Outputs to be relabelled.    current_label_nr: Current label number.    nb_classes: Total number of classes.  # Returns:    Relabelled outputs of a given multi-class dataset into a binary    classification dataset."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/app.py",
            "function": "index()",
            "docstring": "This the the landing page. It includes an upload and submit button  :return:"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/app.py",
            "function": "emptydir()",
            "docstring": ":return:"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/api/python2.7/bin/smtpd2.7.py",
            "function": "process_message(self, peer, mailfrom, rcpttos, data)",
            "docstring": "Override this abstract method to handle messages from the client.    peer is a tuple containing (ipaddr, port) of the client that made the    socket connection to our smtp port.    mailfrom is the raw address the client claims the message is coming    from.    rcpttos is a list of raw addresses the client wishes to deliver the    message to.    data is a string containing the entire full text of the message,    headers (if supplied) and all. It has been `de-transparencied'    according to RFC 821, Section 4.5.2. In other words, a line    containing a `.' followed by other text has had the leading dot    removed.    This function should return None, for a normal `250 Ok' response;    otherwise it returns the desired response string in RFC 821 format."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/api/python2.7/bin/smtpd2.py",
            "function": "process_message(self, peer, mailfrom, rcpttos, data)",
            "docstring": "Override this abstract method to handle messages from the client.    peer is a tuple containing (ipaddr, port) of the client that made the    socket connection to our smtp port.    mailfrom is the raw address the client claims the message is coming    from.    rcpttos is a list of raw addresses the client wishes to deliver the    message to.    data is a string containing the entire full text of the message,    headers (if supplied) and all. It has been `de-transparencied'    according to RFC 821, Section 4.5.2. In other words, a line    containing a `.' followed by other text has had the leading dot    removed.    This function should return None, for a normal `250 Ok' response;    otherwise it returns the desired response string in RFC 821 format."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/sentiment_website/api/python2.7/bin/smtpd.py",
            "function": "process_message(self, peer, mailfrom, rcpttos, data)",
            "docstring": "Override this abstract method to handle messages from the client.    peer is a tuple containing (ipaddr, port) of the client that made the    socket connection to our smtp port.    mailfrom is the raw address the client claims the message is coming    from.    rcpttos is a list of raw addresses the client wishes to deliver the    message to.    data is a string containing the entire full text of the message,    headers (if supplied) and all. It has been `de-transparencied'    according to RFC 821, Section 4.5.2. In other words, a line    containing a `.' followed by other text has had the leading dot    removed.    This function should return None, for a normal `250 Ok' response;    otherwise it returns the desired response string in RFC 821 format."
        },
        {
            "filename": "/Users/harsh/Desktop/coding/jpm-extraction-portal/app.py",
            "function": "getLastCAT1(pathToFile, indexOfPageNumber)",
            "docstring": "Getting the last category from the csv that is stored locally.  :param pathToFile:  :param indexOfPageNumber:  :return:"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/kc/bs_table_extractor.py",
            "function": "_check_validity(self, i, j, height, width)",
            "docstring": "check if a rectangle (i, j, height, width) can be put into self.output"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/kc/bs_table_extractor.py",
            "function": "_check_cell_validity(self, i, j)",
            "docstring": "check if a cell (i, j) can be put into self._output"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/kc/req.py",
            "function": "save_pickle(object, file)",
            "docstring": "A function to save object to a pickle in the file location  :param object: what you want to pickle  :param file: where you want to pickle  :return: None"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/kc/req.py",
            "function": "get_pickle(file)",
            "docstring": "Return the pickle object from the file location  :param file: the place where the pickle is stored  :return: the pickled object"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/kc/req.py",
            "function": "extract_table(inner_html)",
            "docstring": "This function uses the bs_table_extractor library and uses that to extract the table from the pop up.  The return type of extractor.parse() is an Extractor object  The return type of .return_list() is a list  :param inner_html: inner HTML code for the popup  :return: table_extracted of type list of lists"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/kc/req.py",
            "function": "query(r)",
            "docstring": "This function converts the extracted table from list to a Dataframe  :param r: response from the GET request  :return: Dataframe from the list of list"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/leetcodes/solution_file.py",
            "function": "two_sum(nums, target int)",
            "docstring": "Return a list with the index of first two numbers from the nums  parameter that add up to the target.  :param nums: a List with all the numbers  :param target: the Target is the number to which we want to sum the two numbers  :return:"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/leetcodes/solution_file.py",
            "function": "check_palindrome(x int)",
            "docstring": "Return true is the number x is a palindrome, otherwise return a False  :param x: a positive integer  :return: Boolean"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/leetcodes/solution_file.py",
            "function": "nested_list_weight_sum(A list, weight=1)",
            "docstring": "returning the nested sum  :param A:  :return:"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/leetcodes/balloons.py",
            "function": "max_number_of_balloons(text str) -> int",
            "docstring": ">>> max_number_of_balloons('nlaebolko')  1  >>> max_number_of_balloons('loonbalxballpoon')  2  :param text: input from where we want to calculate balloons  :return: the number of balloons"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/search-tool/indexing_files.py",
            "function": "search_elastic(es Elasticsearch, index str, body dict)",
            "docstring": "to search in an elasticsearch database, we need to pass the query in a specific format  It has to contain a json and the index string  :param body: the json  :param index: the string name  :param es: the main Elasticsearch instance  :return:"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/code-search/search/index_files_parser.py",
            "function": "parse_code(file_path str)",
            "docstring": "Function to extract docstring and function string by tokenizing  :param file_path: python file that has to be tokenized  :return: None"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/code-search/search/index_files_parser.py",
            "function": "parse_test(file_path str)",
            "docstring": "function just for testing using dataframe   :param file_path: the filename and filepath  :return: None"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/code-search/search/index_files.py",
            "function": "save_to_json(json_data dict, json_filename str)",
            "docstring": "This is a function to save a dict or json to a .json file  :param json_data: the Python dictionary or json data  :param json_filename: json file to which you want to save this  :return: None"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/code-search/search/index_files.py",
            "function": "search(root, indent=0, flags=None, extension='py')",
            "docstring": "Hello World!  :param root: starting directory  :param indent: for printing in console  :param flags: words to ignore in the path while indexing  :param extension: file extension to index  :return: None"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/ma_scrape.py",
            "function": "get_datetime()",
            "docstring": "Function to return current datetime in format MM/DD/YYYY HH:MM  :return: the string of current datetime"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/ma_scrape.py",
            "function": "convert_cents_to_dollars(x)",
            "docstring": ":param x: the string value in cents  :return: a float value in dollars"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/ma_scrape.py",
            "function": "format_csv()",
            "docstring": "Extracts the useful information from the downloaded csv from the ma_downloads folder in the root directory  and formats it  :return: formatted csv is saved to the ma_csv folder, creates a zip code level csv in the root dir too"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/ma_scrape.py",
            "function": "new_main_scrape(zipcode)",
            "docstring": "This function just goes to the url for the specific zipcode and then clicks on the download button.  The downloaded file is then edited -- renamed and saved to a specific folder  :param zipcode: the specific zipcode for MA  :return: nothing"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/PowerToChoose/csv_generate.py",
            "function": "writeToCSV(csv, data, fact_sheet_paths)",
            "docstring": "given a JSON object containing the data,  write the data to the csv file"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/PowerToChoose/scrapeHelper.py",
            "function": "getCurrentDate()",
            "docstring": ">>> getCurrentDate()    9/22/2019"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/PowerToChoose/scrapeHelper.py",
            "function": "getResponseText(zip_code)",
            "docstring": "Send an API request to PowerToChoose and return the response  Input: 1) the zip code of the city"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/PowerToChoose/scrapeHelper.py",
            "function": "getJSON(zip_code)",
            "docstring": "return a JSON object containing data from the given zip code"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/PowerToChoose/scrapeHelper.py",
            "function": "getEmbeddedPDFLink(link)",
            "docstring": "if there's any embedded links to PDFs, get it"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/PowerToChoose/scrapeHelper.py",
            "function": "getUniquePath(folder_name, preferred_file_name)",
            "docstring": "initial is the name of the file without the extension"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/PowerToChoose/scrapeHelper.py",
            "function": "downloadPDF(link, preferred_file_name, folderName)",
            "docstring": "given an url to a pdf file on a webpage,  download the pdf file locally"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/PowerToChoose/scrapeHelper.py",
            "function": "downloadUsingPDFKit(link, path)",
            "docstring": "There was no reason to use selenium to download pdfs, instead I found this library called pdfkit    pdfkit will convert HTML pages to PDFs, some webpages they have HTML files instead of PDFs,    so pdfkit fixes the problem of converting those HTML pages to PDFs and downloading them    pdfkit depends on wkhtmltopdf    to install pdfkit: run \"pip install pdfkit\"    to install wkhtmltopdf: go to \"https://wkhtmltopdf.org/downloads.html\""
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/bs_table_extractor.py",
            "function": "_check_validity(self, i, j, height, width)",
            "docstring": "check if a rectangle (i, j, height, width) can be put into self.output"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/bs_table_extractor.py",
            "function": "_check_cell_validity(self, i, j)",
            "docstring": "check if a cell (i, j) can be put into self._output"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/req_method.py",
            "function": "timeit(method)",
            "docstring": "Decorator function to time other function  :param method:  :return:"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/req_method.py",
            "function": "check_unique()",
            "docstring": "Returns a tuple with the original merged zipcode supplier companies and the number of unique suppliers  :return:"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/req_method.py",
            "function": "convert_cents_to_dollars(x)",
            "docstring": ":param x: the string value in cents  :return: a float value in dollars"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/req_method.py",
            "function": "get_distribution_companies(zipcode)",
            "docstring": "This function will get all TDU companies for that particular zipcode -- as part of the response  zipcode: zipcode for MA  :return: json response"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/req_method.py",
            "function": "update_tracking(zipcode str, is_new_entry bool, timestamp str, filename str)",
            "docstring": "This function updates the tracking for each zipcode  :param zipcode: zipcode  :param is_new_entry: if there was any changes  :param timestamp: timestamp to put in  :param filename: file name to put in  :return: None"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/req_method.py",
            "function": "get_suppliers(zipcode)",
            "docstring": "This function loops through each of the companies returned from the get_distribution_companies  and gets the supplier's list for each of them  :param zipcode: zipcode  :return: A csv file is saved, returns a Bool value if the zipcode scrape was successful or not"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/req_method.py",
            "function": "scrape()",
            "docstring": "This is the main function to scrape the results  :return: None"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/scrape.py",
            "function": "today_date()",
            "docstring": "Return the current date in the format Date (MM/DD/YY)  :return:"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/scrape.py",
            "function": "sleep_one()",
            "docstring": "Calls the time.sleep function for 1 second. The program run time pauses for 1 sec  :return: None"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/scrape.py",
            "function": "extract_table(inner_html)",
            "docstring": "This function uses the bs_table_extractor library and uses that to extract the table from the pop up.  :param inner_html: inner HTML code for the popup  :return: table_extracted of type list of lists"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/urap-scrape/scrape.py",
            "function": "scrape_website(source_url, zipcode)",
            "docstring": "This is the main function, head for the scraping module that we will write for the New York  website scrape  :return:"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/imgur-scrape-test/imgur_scraper.py",
            "function": "get_viral_posts_from(start_date str, end_date str) -> json",
            "docstring": ":param start_date: date in string  :param end_date: date in string  :return: Imgur's viral content of the specified period in JSON Format"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/expense-tracking/chase/statement_analysis.py",
            "function": "setup()",
            "docstring": "Opens the folder, checks for statment and returns dataframe  :return: dataframe for the csv"
        },
        {
            "filename": "/Users/harsh/Desktop/coding/expense-tracking/chase/statement_analysis.py",
            "function": "analysis(df pd.DataFrame)",
            "docstring": "Analysis of the dataframe  :param df: Dataframe of the csv  :return: None"
        }
    ]
}